import streamlit as st
import pandas as pd
import networkx as nx
import matplotlib
matplotlib.use('Agg') # åå°ç»˜å›¾æ¨¡å¼
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os

# --- 0. é…ç½®å¸¸é‡ä¸æ–‡ä»¶è·¯å¾„ ---
DB_FILE = 'flavor_database.csv'  # æœ¬åœ°å­˜æ¡£æ–‡ä»¶å
FONT_FILE = 'SimHei.ttf'  # <--- æ–°å¢è¿™ä¸€è¡Œ

# --- 1. å­—ä½“é…ç½® (æ ¸å¿ƒä¿®å¤: ä¼˜å…ˆä½¿ç”¨æœ¬åœ°å­—ä½“æ–‡ä»¶) ---
def configure_font():
    # æ–¹æ¡ˆ A: å¦‚æœå½“å‰ç›®å½•ä¸‹æœ‰ SimHei.ttf (äº‘ç«¯éƒ¨ç½²ç¯å¢ƒ)ï¼Œç›´æ¥åŠ è½½å®ƒ
    if os.path.exists(FONT_FILE):
        # å°†å­—ä½“æ³¨å†Œåˆ° matplotlib çš„å­—ä½“ç®¡ç†å™¨ä¸­
        fm.fontManager.addfont(FONT_FILE)
        # è®¾ç½®å…¨å±€é»˜è®¤å­—ä½“ä¸º SimHei
        plt.rcParams['font.sans-serif'] = ['SimHei']
    else:
        # æ–¹æ¡ˆ B: æœ¬åœ°ç”µè„‘ç¯å¢ƒ (æ²¡æœ‰æ”¾ ttf æ–‡ä»¶æ—¶)ï¼Œå°è¯•æŸ¥æ‰¾ç³»ç»Ÿå­—ä½“
        font_names = ['SimHei', 'Microsoft YaHei', 'PingFang SC', 'Heiti TC', 'STHeiti', 'Arial Unicode MS']
        system_fonts = fm.findSystemFonts()
        found_font = None
        for font_path in system_fonts:
            try:
                font_prop = fm.FontProperties(fname=font_path)
                if any(name in font_prop.get_name() for name in font_names):
                    found_font = font_prop
                    break
            except:
                continue
        if found_font:
            plt.rcParams['font.sans-serif'] = [found_font.get_name()]
        else:
            plt.rcParams['font.sans-serif'] = ['sans-serif'] # æœ€åçš„ä¿åº•
            
    plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

configure_font()

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="é£å‘³æ•°æ®åº“ Pro Max (è‡ªåŠ¨å­˜æ¡£ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é£å‘³æ•°æ®åº“åˆ†æç³»ç»Ÿ Pro Max")
st.caption(f"ğŸ’¾ æ•°æ®å°†è‡ªåŠ¨ä¿å­˜è‡³æœ¬åœ°æ–‡ä»¶: {DB_FILE}")

# --- 2. æ•°æ®åº“ç®¡ç† (æ ¸å¿ƒæ–°åŠŸèƒ½) ---

def save_db():
    """å°†å½“å‰ session_state çš„æ•°æ®ä¿å­˜åˆ°æœ¬åœ° CSV"""
    if 'data' in st.session_state and not st.session_state.data.empty:
        try:
            # ä½¿ç”¨ utf-8-sig ç¼–ç ï¼Œé˜²æ­¢ Excel æ‰“å¼€ä¹±ç 
            st.session_state.data.to_csv(DB_FILE, index=False, encoding='utf-8-sig')
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥: {e}")

def load_db():
    """åˆå§‹åŒ–ï¼šå°è¯•ä»æœ¬åœ°åŠ è½½æ•°æ®"""
    if 'data' not in st.session_state:
        if os.path.exists(DB_FILE):
            try:
                df = pd.read_csv(DB_FILE)
                # ç¡®ä¿åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                df = df.astype(str).replace('nan', '')
                st.session_state.data = df
                #ä»¥æ­¤æ–¹å¼é€šçŸ¥ç”¨æˆ·
                # st.toast("âœ… å·²è‡ªåŠ¨åŠ è½½æœ¬åœ°å†å²æ•°æ®") 
            except Exception as e:
                st.error(f"åŠ è½½æœ¬åœ°å­˜æ¡£å¤±è´¥ï¼Œå·²é‡ç½®ä¸ºç©ºåº“: {e}")
                st.session_state.data = pd.DataFrame(columns=['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°'])
        else:
            st.session_state.data = pd.DataFrame(columns=['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°'])

# ç¨‹åºå¯åŠ¨æ—¶ç«‹å³å°è¯•åŠ è½½
load_db()

# --- 3. ä¸šåŠ¡é€»è¾‘å‡½æ•° ---

def load_data_from_excel(file):
    try:
        df = pd.read_excel(file)
        if df.shape[1] >= 3:
            df = df.iloc[:, :3]
            df.columns = ['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°']
            df = df.astype(str).replace('nan', '')
            df = df[df['é£Ÿæ'] != '']
            
            # åˆå¹¶å¹¶å»é‡
            st.session_state.data = pd.concat([st.session_state.data, df]).drop_duplicates().reset_index(drop=True)
            save_db() # ç«‹å³ä¿å­˜
            st.success(f"âœ… æˆåŠŸå¯¼å…¥ {len(df)} æ¡æ•°æ®å¹¶å·²å­˜æ¡£ï¼")
        else:
            st.error("è¡¨æ ¼æ ¼å¼é”™è¯¯")
    except Exception as e:
        st.error(f"å¯¼å…¥å¤±è´¥: {e}")

def smart_add(ing, comp, desc):
    df = st.session_state.data
    new_rows = []
    ing, comp, desc = ing.strip(), comp.strip(), desc.strip()
    
    if ing and comp and desc:
        new_rows.append({'é£Ÿæ': ing, 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å': comp, 'é£å‘³æè¿°': desc})
        msg = f"å·²æ·»åŠ : {ing} - {comp}"
    elif ing and desc and not comp:
        matched_comps = df[df['é£å‘³æè¿°'] == desc]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()
        if len(matched_comps) == 0:
            st.warning(f"âš ï¸ æ— æ³•æ ¹æ®æè¿°â€œ{desc}â€æ¨æ–­ç‰©è´¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ã€‚")
            return
        count = 0
        for m in matched_comps:
            related_descs = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'] == m]['é£å‘³æè¿°'].unique()
            for r in related_descs:
                new_rows.append({'é£Ÿæ': ing, 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å': m, 'é£å‘³æè¿°': r})
            count += 1
        msg = f"âš¡ æ™ºèƒ½æ¨æ–­ï¼šå·²å…³è” {count} ä¸ªç‰©è´¨"
    else:
        st.warning("è¯·è‡³å°‘å¡«å†™ (é£Ÿæ + æè¿°)")
        return

    if new_rows:
        new_df = pd.DataFrame(new_rows)
        st.session_state.data = pd.concat([df, new_df]).drop_duplicates().reset_index(drop=True)
        save_db() # ç«‹å³ä¿å­˜
        st.success(msg)

def clear_db():
    """æ¸…ç©ºæ•°æ®åº“"""
    st.session_state.data = pd.DataFrame(columns=['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°'])
    if os.path.exists(DB_FILE):
        os.remove(DB_FILE)
    st.rerun()

def draw_enhanced_network(selected_ings, selected_comps, secondary_ings):
    """
    ç»˜åˆ¶å¢å¼ºç‰ˆç½‘ç»œå›¾ (ä¿ç•™é‡‘è‰²èŠ‚ç‚¹åŠŸèƒ½)
    """
    fig, ax = plt.subplots(figsize=(16, 12))
    G = nx.Graph()
    
    df = st.session_state.data
    subset = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].isin(selected_comps)]
    
    # 1. è¯†åˆ«å¼ºå…³è”é£Ÿæ (è¿æ¥ >=2 ä¸ªé€‰ä¸­ç‰©è´¨)
    strong_secondary = []
    normal_secondary = []
    
    for ing in secondary_ings:
        connected_comps = subset[subset['é£Ÿæ'] == ing]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()
        if len(connected_comps) >= 2:
            strong_secondary.append(ing)
        else:
            normal_secondary.append(ing)
            
    # 2. æ·»åŠ èŠ‚ç‚¹
    for i in selected_ings:
        G.add_node(i, color='#ff6b6b', size=3000, label=i) # çº¢
    for c in selected_comps:
        G.add_node(c, color='#51cf66', size=1800, label=c) # ç»¿
    for i in strong_secondary:
        if i not in selected_ings:
            G.add_node(i, color='#FFD700', size=2400, label=i) # é‡‘ (Gold)
    for i in normal_secondary:
        if i not in selected_ings:
            G.add_node(i, color='#d0a9f5', size=900, label=i) # ç´«

    # 3. æ·»åŠ è¿çº¿
    for _, row in subset.iterrows():
        ing = row['é£Ÿæ']
        comp = row['é£å‘³ç‰©è´¨åŠè‹±æ–‡å']
        if (ing in selected_ings) or (ing in secondary_ings):
            weight = 2.5 if ing in strong_secondary else 1
            G.add_edge(ing, comp, weight=weight)

    # 4. ç»˜å›¾
    pos = nx.spring_layout(G, k=0.6, seed=42)
    colors = [G.nodes[n].get('color', 'gray') for n in G.nodes]
    sizes = [G.nodes[n].get('size', 100) for n in G.nodes]
    weights = [G[u][v].get('weight', 1) for u,v in G.edges]
    
    nx.draw_networkx_edges(G, pos, edge_color='#cccccc', width=weights, alpha=0.6, ax=ax)
    nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=sizes, alpha=0.95, ax=ax)
    nx.draw_networkx_labels(G, pos, font_family='sans-serif', font_size=10, ax=ax)
    
    ax.set_title(f"é£å‘³å›¾è°±: çº¢(è¾“å…¥) | ç»¿(ç‰©è´¨) | é‡‘(é«˜åŒ¹é…:{len(strong_secondary)}) | ç´«(æ™®é€šå…³è”:{len(normal_secondary)})", fontsize=15)
    ax.axis('off')
    
    st.pyplot(fig)
    plt.close(fig)

# --- ä¸»ç•Œé¢å¸ƒå±€ ---
with st.sidebar:
    st.subheader("1. æ•°æ®åº“ç®¡ç†")
    # æ˜¾ç¤ºå½“å‰æ•°æ®é‡
    row_count = len(st.session_state.data)
    if row_count > 0:
        st.success(f"ğŸ“š å½“å‰åº“ä¸­å·²æœ‰ {row_count} æ¡æ•°æ®")
    else:
        st.warning("ğŸ“š å½“å‰ä¸ºç©ºåº“")
        
    uploaded = st.file_uploader("å¯¼å…¥æ–°Excel (è¿½åŠ æ¨¡å¼)", type='xlsx')
    if uploaded and st.button("ç¡®è®¤å¯¼å…¥"): 
        load_data_from_excel(uploaded)
    
    # æ¸…ç©ºæŒ‰é’®
    with st.expander("ğŸ—‘ï¸ å±é™©æ“ä½œåŒº"):
        if st.button("æ¸…ç©ºæ‰€æœ‰æ•°æ®"):
            clear_db()
    # --- æ–°å¢ï¼šäº‘ç«¯å¤‡ä»½åŠŸèƒ½ (å¼€å§‹) ---
    st.write("---") #ç”¨äºè§†è§‰åˆ†éš”
    st.markdown("### â˜ï¸ äº‘ç«¯æ•°æ®å¤‡ä»½")
    st.caption("âš ï¸ æ³¨æ„ï¼šäº‘ç«¯ç¨‹åºä¼‘çœ åæ•°æ®ä¼šé‡ç½®ï¼Œç¦»å¼€å‰è¯·åŠ¡å¿…ä¸‹è½½å¤‡ä»½ï¼")
    
    # å°†å½“å‰æ•°æ®è½¬æ¢ä¸ºCSVæ ¼å¼
    csv_data = st.session_state.data.to_csv(index=False, encoding='utf-8-sig')
    
    st.download_button(
        label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½å½“å‰æ•°æ®åº“ (.csv)",
        data=csv_data,
        file_name="flavor_database_backup.csv",
        mime="text/csv",
        type="primary"  # è®©æŒ‰é’®æ˜¾ç¤ºä¸ºæ˜¾çœ¼çš„é¢œè‰²
    )
    # --- æ–°å¢ï¼šäº‘ç«¯å¤‡ä»½åŠŸèƒ½ (ç»“æŸ) ---
    st.divider()
    st.subheader("2. æ™ºèƒ½å½•å…¥")
    st.caption("å¡« é£Ÿæ+æè¿° è‡ªåŠ¨å…³è”")
    m_ing = st.text_input("é£Ÿæ")
    m_comp = st.text_input("ç‰©è´¨")
    m_desc = st.text_input("æè¿°")
    if st.button("æ·»åŠ å¹¶ä¿å­˜"): smart_add(m_ing, m_comp, m_desc)

# ä»…å½“ç©ºåº“æ—¶æ˜¾ç¤ºæ¼”ç¤ºæ•°æ®æŒ‰é’®
if st.session_state.data.empty:
    st.info(f"ğŸ‘‹ æ¬¢è¿ï¼æ£€æµ‹åˆ°è¿™æ˜¯æ–°åº“ã€‚è¯·å¯¼å…¥æ•°æ®ï¼Œæˆ–ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç”Ÿæˆæ¼”ç¤ºæ•°æ®ã€‚")
    if st.button("ç”Ÿæˆæ¼”ç¤ºæ•°æ®"):
        demo = {
            'é£Ÿæ': ['è±Œè±†']*3 + ['è¾£æ¤’']*3 + ['æµ‹è¯•A']*2 + ['æµ‹è¯•B']*2,
            'é£å‘³ç‰©è´¨åŠè‹±æ–‡å': ['Comp1', 'Comp2', 'Comp3', 'Comp2', 'Comp3', 'Comp4', 'Comp2', 'Comp3', 'Comp1', 'Comp4'],
            'é£å‘³æè¿°': ['desc']*10
        }
        st.session_state.data = pd.DataFrame(demo)
        save_db() # ä¿å­˜æ¼”ç¤ºæ•°æ®
        st.rerun()

# ä¸»åŠŸèƒ½åŒº
if not st.session_state.data.empty:
    df = st.session_state.data
    tab1, tab2, tab3 = st.tabs(["ğŸ” æœç´¢", "ğŸ•¸ï¸ å›¾è°±(Pro Max)", "ğŸ“‹ æ•°æ®è¡¨"])
    
    with tab1:
        term = st.text_input("æœç´¢å…³é”®è¯ï¼š")
        if term:
            mask = df.apply(lambda x: x.astype(str).str.contains(term, case=False)).any(axis=1)
            st.dataframe(df[mask], use_container_width=True)
            
    with tab2:
        c1, c2 = st.columns([1, 2.5])
        with c1:
            sel_ings = st.multiselect("ç¬¬ä¸€æ­¥ï¼šé€‰é£Ÿæ", sorted(df['é£Ÿæ'].unique()))
            final_comps = []
            if sel_ings:
                st.divider()
                ing_sets = [set(df[df['é£Ÿæ']==i]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å']) for i in sel_ings]
                if len(ing_sets) > 1:
                    shared = set.intersection(*ing_sets)
                else:
                    shared = set()
                
                all_rel = set(df[df['é£Ÿæ'].isin(sel_ings)]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'])
                unique = all_rel - shared
                
                if shared:
                    st.success(f"ğŸ”¥ å…±ç”¨ç‰©è´¨ ({len(shared)})")
                    s1 = st.multiselect("å‹¾é€‰å…±ç”¨", sorted(list(shared)), default=sorted(list(shared)))
                else:
                    s1 = []
                
                st.info(f"ğŸ§Š å…¶ä»–ç‰©è´¨ ({len(unique)})")
                s2 = st.multiselect("å‹¾é€‰ç‰¹æœ‰", sorted(list(unique)))
                final_comps = s1 + s2
                
        with c2:
            if sel_ings and final_comps:
                # äºŒçº§å…³è”é€»è¾‘
                l2 = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].isin(final_comps)]
                sec_ings = [x for x in l2['é£Ÿæ'].unique() if x not in sel_ings]
                
                if sec_ings:
                    # ç»Ÿè®¡å¼ºå…³è”æ•°é‡
                    sub = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].isin(final_comps)]
                    strong_count = 0
                    for si in sec_ings:
                        if len(sub[sub['é£Ÿæ']==si]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()) >= 2:
                            strong_count += 1
                    
                    st.markdown(f"**åˆ†æç»“æœ**ï¼šå…± {len(sec_ings)} ä¸ªå…³è”é£Ÿæï¼Œå…¶ä¸­ **{strong_count} ä¸ªä¸ºé«˜åŒ¹é…åº¦ï¼ˆé‡‘è‰²ï¼‰**")
                
                draw_enhanced_network(sel_ings, final_comps, sec_ings)
            else:
                st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æ•°æ®")
                
    with tab3:
        st.dataframe(df, use_container_width=True)