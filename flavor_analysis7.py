import streamlit as st
import pandas as pd
import networkx as nx
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import plotly.graph_objects as go
import plotly.express as px
import streamlit.components.v1 as components
from pyvis.network import Network
import numpy as np

# --- 0. é…ç½®å¸¸é‡ ---
DB_FILE = 'flavor_database.csv'
FONT_FILE = 'simhei.ttf'

# --- 1. å­—ä½“é…ç½® (ä¿ç•™ç”¨äºMatplotlibå¤‡ç”¨) ---
def configure_font():
    if os.path.exists(FONT_FILE):
        fm.fontManager.addfont(FONT_FILE)
        plt.rcParams['font.sans-serif'] = ['SimHei']
    else:
        # Linux/Cloud ç¯å¢ƒä¸‹å¤‡ç”¨
        plt.rcParams['font.sans-serif'] = ['sans-serif']
    plt.rcParams['axes.unicode_minus'] = False

configure_font()

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="é£å‘³æ•°æ®åº“ æµ‹è¯•2", layout="wide")
st.title("ğŸ§ª é£å‘³æ•°æ®åº“åˆ†æç³»ç»Ÿ æµ‹è¯•2")
st.caption(f"ğŸ’¾ æ•°æ®è‡ªåŠ¨å­˜æ¡£: {DB_FILE}")

# --- 2. æ•°æ®åº“ç®¡ç† ---
def save_db():
    if 'data' in st.session_state and not st.session_state.data.empty:
        try:
            st.session_state.data.to_csv(DB_FILE, index=False, encoding='utf-8-sig')
        except: pass

def load_db():
    if 'data' not in st.session_state:
        if os.path.exists(DB_FILE):
            try:
                df = pd.read_csv(DB_FILE)
                st.session_state.data = df.astype(str).replace('nan', '')
            except:
                st.session_state.data = pd.DataFrame(columns=['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°'])
        else:
            st.session_state.data = pd.DataFrame(columns=['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°'])

load_db()

# --- 3. ä¸šåŠ¡é€»è¾‘ ---
def load_data_from_excel(file):
    try:
        df = pd.read_excel(file)
        if df.shape[1] >= 3:
            df = df.iloc[:, :3]
            df.columns = ['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°']
            df = df.astype(str).replace('nan', '')
            df = df[df['é£Ÿæ'] != '']
            st.session_state.data = pd.concat([st.session_state.data, df]).drop_duplicates().reset_index(drop=True)
            save_db()
            st.success(f"âœ… å¯¼å…¥æˆåŠŸï¼")
        else: st.error("æ ¼å¼é”™è¯¯")
    except Exception as e: st.error(f"å¯¼å…¥å¤±è´¥: {e}")

def smart_add(ing, comp, desc):
    df = st.session_state.data
    new_rows = []
    if ing and comp and desc:
        new_rows.append({'é£Ÿæ': ing, 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å': comp, 'é£å‘³æè¿°': desc})
    elif ing and desc and not comp:
        matched = df[df['é£å‘³æè¿°'] == desc]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()
        if len(matched) == 0:
            st.warning("æ— æ³•æ¨æ–­ç‰©è´¨")
            return
        for m in matched:
            rels = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'] == m]['é£å‘³æè¿°'].unique()
            for r in rels: new_rows.append({'é£Ÿæ': ing, 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å': m, 'é£å‘³æè¿°': r})
    else: return

    if new_rows:
        st.session_state.data = pd.concat([df, pd.DataFrame(new_rows)]).drop_duplicates().reset_index(drop=True)
        save_db()
        st.success("å·²æ·»åŠ ")

def clear_db():
    st.session_state.data = pd.DataFrame(columns=['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å', 'é£å‘³æè¿°'])
    if os.path.exists(DB_FILE): os.remove(DB_FILE)
    st.rerun()

# --- 4. æ ¸å¿ƒï¼šå››ç§å¯è§†åŒ–å¼•æ“ ---

def get_graph_data(selected_ings, selected_comps, secondary_ings):
    """è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€ç”Ÿæˆ NetworkX å›¾å¯¹è±¡å’Œåˆ†ç±»ä¿¡æ¯"""
    G = nx.Graph()
    df = st.session_state.data
    subset = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].isin(selected_comps)]
    
    # è¯†åˆ«å¼ºå…³è”
    strong_sec = []
    normal_sec = []
    for ing in secondary_ings:
        if len(subset[subset['é£Ÿæ'] == ing]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()) >= 2:
            strong_sec.append(ing)
        else:
            normal_sec.append(ing)
            
    # é¢œè‰²æ˜ å°„
    color_map = {
        'input': '#ff6b6b',    # çº¢
        'comp': '#51cf66',     # ç»¿
        'gold': '#FFD700',     # é‡‘
        'normal': '#d0a9f5'    # ç´«
    }
    
    # æ·»åŠ èŠ‚ç‚¹
    for i in selected_ings: G.add_node(i, group='input', color=color_map['input'], size=25, title=f"è¾“å…¥: {i}")
    for c in selected_comps: G.add_node(c, group='comp', color=color_map['comp'], size=15, title=f"ç‰©è´¨: {c}")
    for i in strong_sec: 
        if i not in selected_ings: G.add_node(i, group='gold', color=color_map['gold'], size=20, title=f"é«˜åŒ¹é…: {i}")
    for i in normal_sec:
        if i not in selected_ings: G.add_node(i, group='normal', color=color_map['normal'], size=10, title=f"å…³è”: {i}")

    # æ·»åŠ è¾¹
    for _, row in subset.iterrows():
        ing = row['é£Ÿæ']
        comp = row['é£å‘³ç‰©è´¨åŠè‹±æ–‡å']
        if (ing in selected_ings) or (ing in secondary_ings):
            weight = 3 if ing in strong_sec else 1
            G.add_edge(ing, comp, weight=weight)
            
    return G, color_map

# 1. åŠ¨æ€ç½‘ç»œå›¾ (PyVis)
def viz_interactive_network(G):
    try:
        net = Network(height="600px", width="100%", bgcolor="#ffffff", font_color="black")
        net.from_nx(G)
        # ç‰©ç†å¼•æ“è®¾ç½®ï¼šæ’æ–¥åŠ›ï¼Œé¿å…é‡å 
        net.repulsion(node_distance=150, spring_length=200)
        
        # ä¸´æ—¶ä¿å­˜ä¸º HTML å¹¶è¯»å–
        path = 'temp_network.html'
        net.save_graph(path)
        with open(path, 'r', encoding='utf-8') as f:
            source_code = f.read()
        components.html(source_code, height=600)
        if os.path.exists(path): os.remove(path)
    except Exception as e:
        st.error(f"ç”ŸæˆåŠ¨æ€å›¾å¤±è´¥: {e}")

# 2. æ¡‘åŸºå›¾ (Plotly Sankey)
def viz_sankey(G, color_map):
    # Sankey éœ€è¦ mappingï¼šåå­— -> ç´¢å¼• ID
    nodes = list(G.nodes())
    node_map = {name: i for i, name in enumerate(nodes)}
    
    sources = []
    targets = []
    values = []
    node_colors = []
    
    # ç”ŸæˆèŠ‚ç‚¹é¢œè‰²åˆ—è¡¨
    for node in nodes:
        group = G.nodes[node]['group']
        node_colors.append(color_map[group])
        
    # ç”Ÿæˆè¿çº¿æ•°æ®
    # é€»è¾‘æµå‘ï¼šè¾“å…¥é£Ÿæ(å·¦) -> ç‰©è´¨(ä¸­) -> å…³è”é£Ÿæ(å³)
    # ä½†ç”±äº G æ˜¯æ— å‘å›¾ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å®šå‘
    for u, v in G.edges():
        # åˆ¤æ–­ u å’Œ v è°æ˜¯ç‰©è´¨
        is_u_comp = G.nodes[u]['group'] == 'comp'
        is_v_comp = G.nodes[v]['group'] == 'comp'
        
        if is_u_comp and not is_v_comp: # uæ˜¯ç‰©è´¨ï¼Œvæ˜¯é£Ÿæ
            comp, ing = u, v
        elif not is_u_comp and is_v_comp: # væ˜¯ç‰©è´¨ï¼Œuæ˜¯é£Ÿæ
            comp, ing = v, u
        else:
            continue
            
        # åŒºåˆ†ï¼šæ˜¯è¾“å…¥é£Ÿæè¿˜æ˜¯å…³è”é£Ÿæï¼Ÿ
        if G.nodes[ing]['group'] == 'input':
            # è¾“å…¥ -> ç‰©è´¨
            sources.append(node_map[ing])
            targets.append(node_map[comp])
        else:
            # ç‰©è´¨ -> å…³è”
            sources.append(node_map[comp])
            targets.append(node_map[ing])
        values.append(1) # æƒé‡

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15, thickness=20, line=dict(color="black", width=0.5),
            label=nodes, color=node_colors
        ),
        link=dict(source=sources, target=targets, value=values, color='#E0E0E0')
    )])
    fig.update_layout(title_text="é£å‘³æµå‘å›¾ (æ¡‘åŸºå›¾)", font_size=12, height=600)
    st.plotly_chart(fig, use_container_width=True)

# 3. çƒ­åŠ›çŸ©é˜µå›¾ (Plotly Heatmap)
def viz_heatmap(G):
    # æå–è½´æ•°æ®
    comps = [n for n in G.nodes() if G.nodes[n]['group'] == 'comp']
    ings = [n for n in G.nodes() if G.nodes[n]['group'] != 'comp']
    
    # æ’åºï¼šè®©è¾“å…¥é£Ÿææ’åœ¨æœ€ä¸Šé¢
    ings.sort(key=lambda x: 0 if G.nodes[x]['group'] == 'input' else (1 if G.nodes[x]['group'] == 'gold' else 2))
    
    # æ„å»ºçŸ©é˜µ
    z = []
    for ing in ings:
        row = []
        for comp in comps:
            row.append(1 if G.has_edge(ing, comp) else 0)
        z.append(row)
        
    fig = px.imshow(z, x=comps, y=ings, color_continuous_scale='Greens', aspect="auto")
    fig.update_layout(title="é£å‘³åˆ†å¸ƒçŸ©é˜µ (æ·±è‰²è¡¨ç¤ºå«æœ‰)", height=max(500, len(ings)*15))
    st.plotly_chart(fig, use_container_width=True)

# 4. å¼¦å›¾/åœ†å½¢å›¾ (Plotly Circular)
def viz_chord_circle(G, color_map):
    # ä½¿ç”¨ NetworkX çš„åœ†å½¢å¸ƒå±€è®¡ç®—åæ ‡
    pos = nx.circular_layout(G)
    
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])

    edge_trace = go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=0.5, color='#888'),
        hoverinfo='none', mode='lines')

    node_x = []
    node_y = []
    node_text = []
    node_marker_colors = []
    node_sizes = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
        node_marker_colors.append(color_map[G.nodes[node]['group']])
        node_sizes.append(G.nodes[node]['size'] * 1.5) # ç¨å¾®æ”¾å¤§ä¸€ç‚¹

    node_trace = go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=node_text,
        textposition="top center",
        marker=dict(color=node_marker_colors, size=node_sizes, line_width=1))

    fig = go.Figure(data=[edge_trace, node_trace],
             layout=go.Layout(
                title='é£å‘³å…³è”ç¯ (ä»¿å¼¦å›¾)',
                showlegend=False,
                hovermode='closest',
                margin=dict(b=20,l=5,r=5,t=40),
                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                height=700
             ))
    st.plotly_chart(fig, use_container_width=True)


# --- Sidebar ---
with st.sidebar:
    st.subheader("1. æ•°æ®åº“ç®¡ç†")
    if len(st.session_state.data) > 0: st.success(f"ğŸ“š æ•°æ®é‡: {len(st.session_state.data)}")
    else: st.warning("ğŸ“š ç©ºåº“")
    up = st.file_uploader("å¯¼å…¥Excel", type='xlsx')
    if up and st.button("ç¡®è®¤å¯¼å…¥"): load_data_from_excel(up)
    
    with st.expander("ğŸ—‘ï¸ æ¸…ç©ºåº“"):
        if st.button("ç¡®è®¤æ¸…ç©º"): clear_db()
        
    st.write("---")
    st.markdown("### â˜ï¸ äº‘ç«¯å¤‡ä»½")
    csv_d = st.session_state.data.to_csv(index=False, encoding='utf-8-sig')
    st.download_button("ğŸ“¥ ä¸‹è½½å¤‡ä»½", csv_d, "backup.csv", "text/csv", type="primary")
    
    st.divider()
    st.subheader("2. æ™ºèƒ½å½•å…¥")
    m_i = st.text_input("é£Ÿæ")
    m_c = st.text_input("ç‰©è´¨")
    m_d = st.text_input("æè¿°")
    if st.button("æ·»åŠ "): smart_add(m_i, m_c, m_d)

if st.session_state.data.empty:
    st.info("ğŸ‘‹ è¯·å¯¼å…¥æ•°æ®")
    if st.button("ç”Ÿæˆæ¼”ç¤ºæ•°æ®"):
        demo = {
            'é£Ÿæ': ['è±Œè±†']*3 + ['è¾£æ¤’']*3 + ['æµ‹è¯•A']*2 + ['æµ‹è¯•B']*2 + ['æµ‹è¯•C']*3,
            'é£å‘³ç‰©è´¨åŠè‹±æ–‡å': ['Comp1', 'Comp2', 'Comp3', 'Comp2', 'Comp3', 'Comp4', 'Comp2', 'Comp3', 'Comp1', 'Comp4', 'Comp2', 'Comp5', 'Comp6'],
            'é£å‘³æè¿°': ['æä»å‘³', 'æœé¦™', 'æ²¹è„‚å‘³', 'ç”Ÿé’å‘³', 'æ²¹è„‚å‘³', 'è¾›è¾£', 'æœé¦™', 'æ²¹è„‚å‘³', 'æä»å‘³', 'è¾›è¾£', 'ç”Ÿé’å‘³', 'ç‰¹æ®Šå‘³', 'åšæœå‘³']
        }
        st.session_state.data = pd.DataFrame(demo)
        save_db()
        st.rerun()

# --- Main Logic ---
if not st.session_state.data.empty:
    df = st.session_state.data
    tab1, tab2, tab3 = st.tabs(["ğŸ” ç²¾å‡†æœç´¢", "ğŸ•¸ï¸ é«˜çº§åˆ†æ (Pro)", "ğŸ“‹ æ•°æ®è¡¨"])
    
    with tab1:
        st.subheader("å¤šç»´æ•°æ®æ£€ç´¢")
        c1, c2, c3 = st.columns(3)
        with c1: search_ing = st.text_input("æŒ‰ [é£Ÿæ] æœç´¢", placeholder="å¦‚: è±Œè±†")
        with c2: search_comp = st.text_input("æŒ‰ [é£å‘³ç‰©è´¨] æœç´¢", placeholder="å¦‚: 2-åºšçƒ¯é†›")
        with c3: search_desc = st.text_input("æŒ‰ [é£å‘³æè¿°] æœç´¢", placeholder="å¦‚: ç”Ÿé’å‘³")
        
        st.divider()
        
        # 1. æœé£Ÿæ (è¿˜åŸ V6 é€»è¾‘)
        if search_ing:
            st.markdown(f"#### ğŸ¥¬ é£Ÿæâ€œ{search_ing}â€çš„å…³è”åˆ†æï¼š")
            res = df[df['é£Ÿæ'].str.contains(search_ing, case=False)]
            if not res.empty:
                # èšåˆï¼šæŒ‰é£Ÿæå’Œç‰©è´¨åˆ†ç»„ï¼Œåˆå¹¶æè¿°
                grouped = res.groupby(['é£Ÿæ', 'é£å‘³ç‰©è´¨åŠè‹±æ–‡å'])['é£å‘³æè¿°'].apply(lambda x: 'ã€'.join(x.unique())).reset_index()
                for _, row in grouped.iterrows():
                    st.write(f"ğŸ”¹ **{row['é£Ÿæ']}** â€” `{row['é£å‘³ç‰©è´¨åŠè‹±æ–‡å']}` â€” ï¼ˆ{row['é£å‘³æè¿°']}ï¼‰")
            else:
                st.caption("æœªæ‰¾åˆ°ç›¸å…³é£Ÿæ")
            st.write("---")

        # 2. æœç‰©è´¨ (è¿˜åŸ V6 é€»è¾‘)
        if search_comp:
            st.markdown(f"#### ğŸ§ª ç‰©è´¨â€œ{search_comp}â€çš„åˆ†å¸ƒæƒ…å†µï¼š")
            res = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].str.contains(search_comp, case=False)]
            if not res.empty:
                # ä»¥ç‰©è´¨ä¸ºæ ¸å¿ƒèšåˆ
                target_comps = res['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()
                for comp in target_comps:
                    sub = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'] == comp]
                    ings = 'ã€'.join(sub['é£Ÿæ'].unique())
                    descs = 'ã€'.join(sub['é£å‘³æè¿°'].unique())
                    st.write(f"ğŸ”¸ ï¼ˆåŒ…å«é£Ÿæï¼š{ings}ï¼‰â€” **`{comp}`** â€” ï¼ˆ{descs}ï¼‰")
            else:
                st.caption("æœªæ‰¾åˆ°ç›¸å…³ç‰©è´¨")
            st.write("---")

        # 3. æœæè¿° (è¿˜åŸ V6 é€»è¾‘ - åŒ…å«é«˜äº®)
        if search_desc:
            st.markdown(f"#### ğŸ‘ƒ æè¿°â€œ{search_desc}â€çš„åå‘æ£€ç´¢ï¼š")
            res = df[df['é£å‘³æè¿°'].str.contains(search_desc, case=False)]
            if not res.empty:
                # æ‰¾åˆ°ç¬¦åˆæè¿°çš„ç‰©è´¨
                target_comps = res['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()
                for comp in target_comps:
                    # è·å–è¯¥ç‰©è´¨çš„å®Œæ•´ä¿¡æ¯
                    sub = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'] == comp]
                    ings = 'ã€'.join(sub['é£Ÿæ'].unique())
                    
                    # --- æ ¸å¿ƒä¿®å¤ï¼šå¤„ç†æè¿°é«˜äº® ---
                    all_descs_list = sub['é£å‘³æè¿°'].unique()
                    highlighted_descs = []
                    for d in all_descs_list:
                        if search_desc in d:
                            # Markdown é«˜äº®
                            highlighted_descs.append(f"**{d}**")
                        else:
                            highlighted_descs.append(d)
                    descs_str = 'ã€'.join(highlighted_descs)
                    
                    st.write(f"âœ¨ ï¼ˆåŒ…å«é£Ÿæï¼š{ings}ï¼‰â€” å« **{search_desc}** çš„ç‰©è´¨ `{comp}` â€” ï¼ˆ{descs_str}ï¼‰")
            else:
                st.caption("æœªæ‰¾åˆ°ç›¸å…³æè¿°")

    with tab2:
        c_left, c_right = st.columns([1, 3])
        with c_left:
            st.markdown("### 1. é€‰é£Ÿæ")
            all_ings = sorted(df['é£Ÿæ'].unique())
            sel_ings = st.multiselect("é£Ÿæ (1-5ä¸ª)", options=all_ings)
            
            final_comps = []
            if sel_ings:
                subset = df[df['é£Ÿæ'].isin(sel_ings)]
                st.markdown("### 2. é€‰ç‰¹å¾ (å¯é€‰)")
                descs = sorted(subset['é£å‘³æè¿°'].unique())
                f_descs = st.multiselect("ç‰¹å¾ç­›é€‰", options=descs)
                if f_descs:
                    v = subset[subset['é£å‘³æè¿°'].isin(f_descs)]['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].unique()
                    subset = subset[subset['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].isin(v)]
                
                st.markdown("### 3. é€‰ç‰©è´¨")
                # é€»è¾‘åˆ†ç±»
                owners = {}
                for _, row in subset.iterrows():
                    c, i = row['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'], row['é£Ÿæ']
                    if c not in owners: owners[c] = set()
                    owners[c].add(i)
                
                shared_all, shared_some, unique_map = [], [], {i:[] for i in sel_ings}
                for c, oss in owners.items():
                    if len(oss) == len(sel_ings) and len(sel_ings)>1: shared_all.append(c)
                    elif len(oss) >= 2: shared_some.append(c)
                    elif len(oss) == 1: unique_map[list(oss)[0]].append(c)
                
                if shared_all: final_comps.extend(st.multiselect("ğŸ”¥ å…¨å…±ç”¨", sorted(shared_all), default=sorted(shared_all)))
                if shared_some: final_comps.extend(st.multiselect("ğŸ”— éƒ¨åˆ†å…±ç”¨", sorted(shared_some), default=sorted(shared_some)))
                st.caption("ğŸ§Š ç‰¹æœ‰ç‰©è´¨")
                for i, cs in unique_map.items():
                    if cs: final_comps.extend(st.multiselect(f"{i} ç‰¹æœ‰", sorted(cs)))
                    
        with c_right:
            if sel_ings and final_comps:
                # å¯»æ‰¾äºŒçº§å…³è”
                l2 = df[df['é£å‘³ç‰©è´¨åŠè‹±æ–‡å'].isin(final_comps)]
                sec_ings = [x for x in l2['é£Ÿæ'].unique() if x not in sel_ings]
                
                # æ„é€ å›¾æ•°æ®
                G, color_map = get_graph_data(sel_ings, final_comps, sec_ings)
                
                # --- æ–°å¢ï¼šå¯è§†åŒ–ç±»å‹é€‰æ‹© ---
                st.markdown("### 4. åˆ†æè§†å›¾ (NEW)")
                viz_type = st.radio(
                    "é€‰æ‹©ä¸€ç§è§‚å¯Ÿè§†è§’ï¼š",
                    ["ğŸ•¸ï¸ äº¤äº’å¼åŠ¨æ€ç½‘ç»œ (ç‰©ç†æ¨¡æ‹Ÿ)", "ğŸŒŠ æ¡‘åŸºæµå‘å›¾ (é€»è¾‘æ¸…æ™°)", "ğŸ“Š çƒ­åŠ›çŸ©é˜µå›¾ (åˆ†å¸ƒå¯†åº¦)", "â­• å¼¦çŠ¶ç¯å½¢å›¾ (æ•´ä½“å…³è”)"],
                    horizontal=True
                )
                
                st.divider()
                
                if "äº¤äº’" in viz_type:
                    viz_interactive_network(G)
                elif "æ¡‘åŸº" in viz_type:
                    viz_sankey(G, color_map)
                elif "çƒ­åŠ›" in viz_type:
                    viz_heatmap(G)
                elif "å¼¦çŠ¶" in viz_type:
                    viz_chord_circle(G, color_map)
                    
            elif not sel_ings:
                st.info("ğŸ‘ˆ è¯·ä»å·¦ä¾§å¼€å§‹")

    with tab3:
        st.dataframe(df, use_container_width=True)